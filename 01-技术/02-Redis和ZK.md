# Redis为什么这么快
最大负载数量级10W qps
## 线程模型
NIO + 多路复用
非阻塞IO：Redis使用多路复用IO技术，在poll，epool，kqueue选择最优IO实现
Redis可以在单线程中监听多个Socket的请求，在任意一个Socket可读/可写时，Redis去读取客户端请求，在内存中操作对应的数据，然后再写回到Socket中。整个过程非常高效，Redis利用了IO多路复用技术的事件驱动模型，保证在监听多个Socket连接的情况下，只针对有活动的Socket采取反应。


## 单线程
Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销
单线程模型还带了以下好处

- 没有了多线程上下文切换的性能损耗
- 没有了访问共享资源加锁的性能损耗
- 开发和调试非常友好，可维护性高
## 优化的数据结构
优化的数据结构
## 内存存储
使用内存存储,没有磁盘IO上的开销
​



# Redis的客户端
## Lettuce(spring默认)
jedis
![](https://youpaiyun.zongqilive.cn/image/image (1).png)
Jedis 管理连接池


redis main函数执行流程
​





# Redis的数据类型
## 常用5种数据类型
### string
### hash
### list
### set
### zset
#### 压缩列表

- 元素数量少于128的时候
- 每个元素的长度小于64字节
#### 跳表 (跳表原理)

时间复杂度平均能达到`O(log n)`

##### 跳表时间复杂度计算


时间复杂度 = 索引的高度 * 每层索引遍历元素的个数。


假设 每一层索引的结点数量都是低层索引的一半。

原始链表有n个结点，那么索引的层级就是log(n)-1，, 跳表的总高度是 logn-1 +1= logn,  在每一层的访问次数是常量(K)，因此查找结点的平均时间复杂度是O（K * logn）,省略常数O(logn)
​


## 其他数据类型
### bitmap
位图不是实际的数据类型，而是在String类型上定义的一组面向位的操作。
由于字符串是二进制安全的，最大长度是512MB,转换成位可以设置 2^32不同的位。
512MB = 2^9  2^3（byte）  2^10（kb） * 2^10(mb) = 2^32（bit）
位图的最大优点之一，存储信息时可以节省大量空间。


Bitmap使用情景
各种实时分析。
例如，假设您想知道网站用户每天访问量最长的时间。您从零开始计算天数，即从您公开网站的那一天开始，并在用户每次访问该网站时对SETBIT进行设置。作为位索引，您只需花费当前的unix时间，减去初始偏移，然后除以3600 * 24。
这样，对于每个用户，您都有一个小的字符串，其中包含每天的访问信息。


> setbit key 20200310-UID 1
setbit key 20200311-UID 1
setbit key 20200311-UID 0



类似bloomfilter的实现，防止缓存穿透。（将存量 + 增量的标识数据进行存储，去判断）
可以通过多个bitmap的交集、并集、not(非)、xor(疑惑)操作处理一些位运算的逻辑


### HyperLogLog(统计)
属于一种概率算法
HyperLogLog优点，在输入元素的数量或者体积非常大时。计算基数所需的空间总是固定很小的。每个HyperLogLog的键只需要花费12KB内存，在标准误差0.81%的前提下，就可以计算接近2^64个不同的基数。
用bitmap存储1一亿个统计数据大概需要12M内存；而在HLL中，只需要不到1K内存就能做到。


HyperLogLog只会根据输入元素来计算基数，而不会存储元素本身，所以不能返回各个元素。


HLL的使用场景：常用来统计一个集合中不重复的元素个数，例如网站PV，搜索关键词数量，数据分析、网络监控及数据库优化等领域。
HLL比 bitmap更节省内存，但有一定误差( 标准误差 0.81%)


### Geospatial Indexes(地理空间索引)
将制定的地理空间位置(经度、纬度、名称)添加到指定的key中。这些数据将会存储到Sorted set中。目的是为了方便GEORADIUS或者GEORADIUSBYMEMBER命令对数据进行半径查询等操作


### Streams(忽略)




#BitMap 

# 布隆过滤器
它可能会误判。当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。

优点:

- 是由一串二进制数组组成的数据, 占用空间小

- 查询速度快, 根据位置下标获取数据, O(K), K-表示哈希函数的个数

缺点:

- 删除不友好, 可能存在误删

- 误判,( 不同数据的hash值可能是相同的, ), 只能减少误判的概率

如何减少误判的概率?

- 不能设置的非常小, 根据业务情况

- Hash函数的个数

- 误差率越小, 占用的空间越大, 需要的Hash函数越多 

![](https://youpaiyun.zongqilive.cn/image/20210601192728.png)

查询过程:

-  算出 "你好" 的下标位置, 如 (3, 5,7) 这三这位置;

- 位置上的数据 必须都是1 , 就存在, 否则 不存在

删除数据

很难做删除操作, 会造成数据的误删

![](https://youpaiyun.zongqilive.cn/image/20210601192822.png)

例如: "你好"和"hello" 在同一位置, 无法选择性的删除其中一个

# 布谷鸟过滤器

鸠占鹊巢 , 把挤走的元素找新的位置

挤兑循环问题




# Redis 的过期策略


## 定期删除


## 懒惰删除


## 淘汰策略(LRU和LFU)


LFU 表示按最近的访问频率进行淘汰，它比 LRU 更加精准地表示了一个 key 被访问的热度。


如果一个 key 长时间不被访问，只是刚刚偶然被用户访问了一下，那么在使用 LRU 算法下它是不容易被淘汰的，因为 LRU 算法认为当前这个 key 是很热的。而 LFU 是需要追踪最近一段时间的访问频率，如果某个 key 只是偶然被访问一次是不足以变得很热的，它需要在近期一段时间内被访问很多次才有机会被认为很热。


# 缓存雪崩-- 大量的key同时失效


解决方案:


1. 分散过期时间
1. 在缓存失效之后, 通过加锁或者队列来控制读数据库写缓存的线程数量, 保证同一时间只有一个线程再写数据,其他线程等待
1. 双key策略, 主key设置过期时间,备key永久, 主key过期, 返回备key的内容
1. 后台更新, 定时更新, 消息队列通知更新



# 缓存击穿 -- 频繁访问的热点数据过期
像子弹一样, 集中某一点持续射击
解决方案

1. 数据用不过期, 由后台更新
1. 互斥锁, 保证对于每个key同时只有一个线程去查询后端服务



# 缓存穿透-- 查询不存在数据
解决方案

1. 非法请求的限制
1. 缓存空值或者默认值
1. 使用布隆过滤器快速判断数据是否存在



# 缓存和数据库双写不一致
## 延时双删策略
最后一步的删除可以作为异步操作, 就是防止有客户端读取的时候设置了旧值


```
1）先删除缓存
2）再写数据库
3）休眠500毫秒（根据具体的业务时间来定）
4）再次删除缓存。
那么，这个500毫秒怎么确定的，具体该休眠多久呢？
读DB并写入redis的时间
需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。
当然，这种策略还要考虑 redis 和数据库主从同步的耗时。最后的写数据的休眠时间：则在读数据业务逻辑的耗时的基础上，加上几百ms即可。比如：休眠1秒。
```


## 删除缓存重试机制
如果第二步的删除缓存失败呢，删除失败会导致脏数据哦~
删除失败就多删除几次呀,保证删除缓存成功呀~ 所以可以引入删除缓存重试机制
```java
写请求更新数据库
缓存因为某些原因，删除失败
把删除失败的key放到消息队列
消费消息队列的消息，获取要删除的key
重试删除缓存操作
```
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1011530/1621567375329-469c197f-613f-4e5f-b773-b4aef1ebc74b.png#clientId=ua026df69-fc46-4&from=paste&height=598&id=uac502d5f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=598&originWidth=1084&originalType=binary&size=106525&status=done&style=none&taskId=uffc6bbff-91dc-4cdc-9aaa-22affbeb257&width=1084)
## 订阅数据库的 binlog
重试删除缓存机制还可以，就是会造成好多业务代码入侵。其实，还可以通过数据库的binlog来异步淘汰key。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1011530/1621567572311-8baf38a2-0e92-4a9b-a18a-19fe70149d72.png#clientId=ua026df69-fc46-4&from=paste&height=618&id=uc227eb16&margin=%5Bobject%20Object%5D&name=image.png&originHeight=618&originWidth=1009&originalType=binary&size=108270&status=done&style=none&taskId=u02f6ef25-a185-495a-acf3-1aa7cfa795d&width=1009)
​

# 数据持久化
## 快照同步(RDB)
快照同步是在主库上进行一次 bgsave 将当前内存的数据全部快照到磁盘文件中，然后再将快照文件的内容全部传送到从节点。从节点接收到数据完毕后，立即执行一次全量加载，加载之前先要将当前内存的数据清空。加载完毕后通知主节点继续进行增量同步。
快照同步极易产生死循环，所以务必配置一个合适的复制 buffer 大小参数，避免快照复制的死循环。
## 增量同步（AOF）
在Redis重启的时候；AOF和dump同时存在的时候，先找谁？
先找AOF文件，如果AOF有问题，Redis是启动不了的。
​

增量同步的是对状态产生修改性影响的指令流。先同步到本地的Buffer，然后再异步的传输给从节点，从节点一般同步主节点状态，一般想主节点反馈同步的偏移量。
Redis 的复制内存 buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容。所以在网络通信不佳的情况下， 可能会导致还未被同步的数据被覆盖掉。所以需要快照同步。
### rewrite

- 是什么： 
   - AOF采用文件追加方式，文件会越来越大。为避免出现此种情况，新增了重写机制， 当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集。可以使用命令bgrewriteaof
- 重写原理 
   - AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)， 遍历新进程的内存中数据，每条记录有一条的Set语句。重写aof文件的操作，并没有读取旧的aof文件， 而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似
- 触发机制 
   - Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发 (在redis.conf中的auto-aof-rewrite-min-size 64mb配置)



## RDB和AOF 总结
### RDB
优势:
适合大规模的数据恢复
对数据完整性和一致性要求不高
劣势:
在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改(因为保存一次有时间间隔)
Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑
### AOP
优势:
每秒记录 如果一秒内宕机，有数据丢失
劣势:
 相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb
​

# Redis-Cluster
Redis Cluster划分了16384个slots，每个节点负责其中的一部分数据。slot的信息存储在每个节点中，节点会将slot信息持久化到配置文件中.
对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot。
​

当客户端连接时，会获得一份slot的信息。这样当客户端需要访问某个key时，就可以直接根据缓存在本地的slot信息来定位节点。
## MOVED重定向
如果key所属的槽位由该节点提供服务，那么就直接返回结果。否则就会返回一个MOVED错误
GET x 
-MOVED 3999 127.0.0.1:6381
这个错误包括了对应的key属于哪个槽位（3999）以及该槽位所在的节点的IP地址和端口号。client收到这个错误信息后，就将这些信息存储起来以便可以更准确的找到正确的节点。
​

当客户端收到MOVED错误后, 也会更新集群的分布信息
​

## ASK重定向
在Redis Cluster迁移的时候会用到ASK重定向，
​

## MOVED和ASK的区别
1）ASK 是一种迁移槽临时措施，只是会产生一次重定向​
2）MOVED 代表该槽已经完全由另一个节点负责了，会触发客户端刷新本地路由表，之后对于该槽的请求都会请求新的节点。
​

# BigKey问题
redis-cli --bigkeys 可以命令统计bigkey的分布。
判断一个key是否为bigkey，只需要执行 debug object key 查看serializedlength属性即可，它表示key对应的value序列化之后的字节数，
## 删除 bigkey
先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除
## 拆分
可以考虑拆分成多个 key-value
## 不用Redis
考虑文档型数据库如：MongoDB等


# redis相比memcached

1. Redis支持更为丰富的数据类型
1. Redis可以持久化其数据
1. 




# 分布式锁实现
## Redis实现
### 获取锁- set命令
SET resource_name unique_value NX PX  30000value 要具有唯一性，可以使用UUID.randomUUID().toString()方法生成，用来标识这把锁是属于哪个请求加的，在解锁的时候就可以有依据；
（unique_value可以是UUID等）


### 释放锁- 防止误解锁
释放锁时要验证 value 值，防止误解锁；
通过 Lua 脚本来避免 Check And Set 模型的并发问题，因为在释放锁的时候因为涉及到多个Redis操作 （利用了eval命令执行Lua脚本的原子性）
```shell
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```
### 锁的过期时间
#### 确保过期时间大于业务执行时间问
为了防止多个线程同时执行业务代码，需要确保过期时间大于业务执行时间
增加一个boolean类型的属性isOpenExpirationRenewal，用来标识是否开启定时刷新过期时间
在增加一个scheduleExpirationRenewal方法用于开启刷新过期时间的线程
加锁代码在获取锁成功后将isOpenExpirationRenewal置为true，并且调用scheduleExpirationRenewal方法，开启刷新过期时间的线程
解锁代码增加一行代码，将isOpenExpirationRenewal属性置为false，停止刷新过期时间的线程轮询
##### Redisson实现
获取锁成功就会开启一个定时任务,定时任务会定期检查去续期
该定时调度每次调用的时间差是internalLockLeaseTime / 3,也就10秒
默认情况下,加锁的时间是30秒.如果加锁的业务没有执行完,那么到 30-10 = 20秒的时候,就会进行一次续期,把锁重置成30秒
​

### 主节点挂掉
如果存储锁对应key的那个节点挂了的话，就可能存在丢失锁的风险，导致出现多个客户端持有锁的情况，这样就不能实现资源的独享了。
客户端A从master获取到锁
在master将锁同步到slave之前，master宕掉了（Redis的主从同步通常是异步的）。
主从切换，slave节点被晋级为master节点
客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。导致存在同一时刻存不止一个线程获取到锁的情况。
#### redlock算法
这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把锁：

1. 获取当前时间戳，单位是毫秒；
1. 跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；
1. 尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1；
1. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
1. 要是锁建立失败了，那么就依次之前建立过的锁删除；
1. 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。



也就是说，假设锁30秒过期，三个节点加锁花了31秒，自然是加锁失败了
RedLock问题：
RedLock 只是保证了锁的高可用性，并没有保证锁的正确性
RedLock 是一个严重依赖系统时钟的分布式系统

# ZK


## 四种类型的znode


永久节点


永久有序节点


临时节点


临时有序节点
