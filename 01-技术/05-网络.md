https://juejin.cn/post/6976058874310688805



https://www.cnblogs.com/orgliny/p/5780796.html

# 7层模型（TCP4层)

![](https://youpaiyun.zongqilive.cn/image/20210306185251.png)

![](https://youpaiyun.zongqilive.cn/image/20210306185124.png)



# TCP协议

`面向连接的`, `可靠的`, `基于字节流`的传输层通信协议

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议 可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
- **字节流**：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节已经收到，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。

![](https://youpaiyun.zongqilive.cn/image/20210208185249.png)



## TCP三次握手

![](https://youpaiyun.zongqilive.cn/image/20210208170031.png)

1. 客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。
2. 客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。(第一次握手)
3. 服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。(第二次握手)
4. 客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。(第三次握手)

### 为什需要三次握手
目的是: 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误

`已失效的连接请求报文段`的产生在这样一种情况下：
client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。
本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接

假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”。主要目的防止server端一直等待，浪费资源。

## TCP四次挥手
![](https://youpaiyun.zongqilive.cn/image/20210208190722.png)
1. 第一次挥手:
	Client发送一个FIN, 用来关闭CLient到Server的数据传递, Client进入FIN_WAIT_1状态
2. 第二次挥手: 
	Server收到FIN后, 发送ACK给Client, 确认序号维收到的序号+1,  Server进入CLOSE_WAIT状态
	客户端收到服务器的ACK报文后，客户端变为 FIN_WAIT2状态
3. 第三次挥手:
	Server发送一个FIN, 用来关闭Server到Client的数据传递, Server进入LAST_ACK状态
4. 第四次挥手:
	Client收到FIN后,接着发送一个ACK给Server, Client进入TIME_WAIT状态,  确认序号为收到的序号+1, Server进入CLOSE状态, 完成四次挥手.
	客户端经过2MSL(max segment lifetime，报文最大生存时间)时间后，也变为 CLOSED状态

### 为需要是四次挥手
- 服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。

### TIME_WAIT 状态
> 主动关闭连接的，才有 TIME_WAIT 状态

#### 为什么需要TIME_WAIT状态
1. 阻止延迟数据段
	防止延迟的数据段被其他使用相同源地址、源端口、目的地址以及目的端口的 TCP 连接收到；
2. 保证连接关闭
	保证 TCP 连接的远程被正确关闭，即等待被动关闭连接的一方收到 FIN 对应的 ACK 消息；

只要客户端等待 2 MSL 的时间，客户端和服务端之间的连接就会正常关闭，新创建的 TCP 连接收到影响的概率也微乎其微，保证了数据传输的可靠性

#### TIME_WAIT 过多的危害
- 第一是内存资源占用；
- 第二端口耗尽，一个 TCP 连接至少消耗一个本地端口；

#### 几个核心疑问
1. time_wait 是「服务器端」的状态？or 「客户端」的状态？
RE：time_wait 是「主动关闭 TCP 连接」一方的状态，可能是「客服端」的，也可能是「服务器端」的
一般情况下，都是「客户端」所处的状态；「服务器端」一般设置「不主动关闭连接」

2. 服务器在对外服务时，是「客户端」发起的断开连接？还是「服务器」发起的断开连接？
正常情况下，都是「客户端」发起的断开连接
「服务器」一般设置为「不主动关闭连接」，服务器通常执行「被动关闭」
但 HTTP 请求中，http 头部 connection 参数，可能设置为 close，则，服务端处理完请求会主动关闭 TCP 连接


####  解决办法：
- 客户端
	HTTP 请求的头部，connection 设置为 keep-alive，保持存活一段时间：现在的浏览器，一般都这么进行了
- 服务器端
允许 time_wait 状态的 socket 被重用
缩减 time_wait 时间，设置为 1 MSL（即，2 mins）



## TCP粘包,半包
粘包：指的是发送端在多次发送数据的过程中，数据包在同一个数据流中传输给了接收端，此现象就称之为粘包
半包：发送端发送的数据大于发送缓冲区，接收端一次接收的数据不是完整的数据，此现象称之为半包

拆包：
1. 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
2. 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。

粘包：
1. 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。
2. 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

![](https://youpaiyun.zongqilive.cn/image/20210801112320.png)


### 常规的解决方法- 定义消息边界
1. 长度边界
应用层在发送消息的时候指定每个消息的固定长度，比如固定每个消息为1K，那么当发送时消息不满1K时，用固定的字符串填充，当接收方读取消息的时候，每次也截取1k长度的流作为一个消息l来解析。这种方式的问题在于应用层不能发送超过1K大小的数据，所以使用这种方式的前提知道了消息大小会在哪个范围之内，如果不能确定消息的大小范围不太适合用这种方式，这样会导致大的消息发出去会有问题，小的消息又需要大量的数据填充，不划算。
2. 符号边界
应用层在发送消息前和发送消息后标记一个特殊的标记符，比如 &符号，当接收方读取消息时，根据&符号的流码来截取消息的开始和结尾。这种方式的问题在于发送的消息内容里面本身就包含用于切分消息的特殊符号，所以在定义消息切分符时候尽量用特殊的符号组合。
3. 组合边界 - 推荐
这种方式先是定义一个Header+Body格式，Header消息头里面定义了一个开始标记+一个内容的长度，这个内容长度就是Body的实际长度，Body里面是消息内容，当接收方接收到数据流时，先根据消息头里的特殊标记来区分消息的开始，获取到消息头里面的内容长度描述时，再根据内容长度描述来截取Body部分。


### 数据聚集的Nagle算法
Nagle 算法是一种通过减少数据包的方式提高 TCP 传输性能的算法

当应用层协议通过 TCP 协议传输数据时，实际上待发送的数据先被写入了 TCP 协议的缓冲区，如果用户开启了 Nagle 算法，那么 TCP 协议可能不会立刻发送写入的数据，它会等待缓冲区中数据超过最大数据段（MSS）或者上一个数据段被 ACK 时才会发送缓冲区中的数据。

Nagle 算法确实能够在数据包较小时提高网络带宽的利用率并减少 TCP 和 IP 协议头带来的额外开销，但是使用该算法也可能会导致应用层协议多次写入的数据被合并或者拆分发送，当接收方从 TCP 协议栈中读取数据时会发现不相关的数据出现在了同一个数据段中，应用层协议可能没有办法对它们进行拆分和重组。

### UDP没有半包和粘包问题
因为TCP是面向连接的传输协议，TCP传输的数据是以流的形式，而流数据是没有明确的开始结尾边界，所以TCP也没办法判断哪一段流属于一个消息。而UDP是没有半包、粘包的问题，因为UPD是面向消息的，它有边界协议，消息是有格式的, 可以根据消息的格式区分消息的开始和结尾，UDP和TCP两个发送消息就好像一个用桶运水，一个用水管运水，用水管运水的你是没办法区分那部分的水是属于哪一桶的。

## TCP的可靠传输
### 数据包校验
目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据；
### 对失序数据包重排序
既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；

### 丢弃重复数据
对于重复数据，能够丢弃重复数据；

### 应答机制
当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；

### 重传机制
超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；

### 流量控制
流量控制是避免「发送方」的数据填满「接收方」的缓存
TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。

### 拥塞控制
拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….
所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量

如何判断当前网络拥塞?
其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了用拥塞。

#### 慢启动
TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量
慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，就拥塞窗口 cwnd 的大小就会加 1。

这里假定拥塞窗口 cwnd 和发送窗口 swnd 相等，下面举个栗子：

- 连接建立完成后，一开始初始化 cwnd = 1，表示可以传一个 MSS 大小的数据。
- 当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个
- 当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个
- 当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。

#### 拥塞避免
当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。
一般来说 `ssthresh` 的大小是 `65535` 字节。
那么进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**
接上前面的慢启动的栗子，现假定 `ssthresh` 为 `8`：
 8个ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 `MSS` 大小的数据，变成了线性增长
![](https://youpaiyun.zongqilive.cn/image/20210209103247.png)
所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。
就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。
当触发了重传机制，也就进入了「拥塞发生算法」。

#### 速重传和快速恢复
![](https://youpaiyun.zongqilive.cn/image/20210209103709.png)




![](https://youpaiyun.zongqilive.cn/image/20210208194223.png)
















# backlog概念-半连接和全连接

https://mp.weixin.qq.com/s/Y3rmbwPur1n1P0E_hgp3Kg

backlog的定义是已连接但未进行accept处理的SOCKET队列大小,如果这个队列满了，将会发送一个ECONNREFUSED错误信息给到客户端。

在linux 2.2以前，backlog大小包括了半连接状态和全连接状态两种队列大小。

linux 2.2以后，分离为两个backlog来分别限制半连接SYN_RCVD状态的未完成连接队列大小跟全连接ESTABLISHED状态的已完成连接队列大小。

两种实现方式而言，作者给出了比较详细的分析：

1. 第一种实现方式在底层维护一个由backlog指定大小的队列。服务端收到SYN后，返回一个SYN/ACK，并把连接放入队列中，此时这个连接的状态是SYN_RECEIVED。当客户端返回ACK后，此连接的状态变为ESTABLISHED。队列中只有ESTABLISHED状态的连接能够交由应用处理。第一种实现方式可以简单概括为：一个队列，两种状态。
2. 第二种实现方式在底层维护一个SYN_RECEIVED队列和一个ESTABLISHED队列，当SYN_RECEIVED队列中的连接返回ACK后，将被移动到ESTABLISHED队列中。backlog指的是ESTABLISHED队列的大小。





- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accepet 队列；

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。

![](https://youpaiyun.zongqilive.cn/image/20210707195228.png)



# HTTP

请求幂等性

- http 协议头相关
- http/https 1.0、1.1、2.0
- 网络攻击（CSRF、XSS）









# url到页面的过程















